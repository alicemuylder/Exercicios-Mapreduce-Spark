{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a9948e",
   "metadata": {},
   "source": [
    "O código é um WordCount usando PySpark, ou seja, ele conta quantas vezes cada palavra aparece em um texto. Ele faz isso usando três abordagens diferentes do Spark: RDD API, DataFrame API e SQL API.\n",
    "\n",
    "1️⃣ RDD API\n",
    "RDD = Resilient Distributed Dataset, a forma mais básica do Spark de trabalhar com dados.\n",
    "Aqui você manipula listas distribuídas de linhas com funções como map, flatMap e reduceByKey.\n",
    "É mais manual e detalhado, você controla cada passo do processamento.\n",
    "\n",
    "2️⃣ DataFrame API\n",
    "DataFrame = tabela de dados estruturada, parecido com Excel ou pandas.\n",
    "Permite escrever operações usando funções de alto nível do Spark, como groupBy, count, explode.\n",
    "Mais rápido que RDD porque o Spark otimiza as operações automaticamente.\n",
    "\n",
    "3️⃣ SQL API\n",
    "Usa queries SQL diretamente sobre os dados do Spark.\n",
    "Você cria uma tabela temporária (createOrReplaceTempView) e escreve SQL normal para contar palavras.\n",
    "É muito parecido com DataFrame, mas quem gosta de SQL pode achar mais intuitivo.\n",
    "\n",
    "Conclusões:\n",
    "Todas as três abordagens dão os mesmos resultados.\n",
    "DataFrame e SQL normalmente são mais rápidos que RDD, por causa das otimizações do Spark.\n",
    "Código é escalável, funciona com textos muito grandes sem mudar nada.\n",
    "Demonstra como limpar dados e contar palavras de forma eficiente em Big Data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
