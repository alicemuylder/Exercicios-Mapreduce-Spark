# Atividade MapReduce e Spark â€” Alice De Muylder

Este repositÃ³rio contÃ©m as implementaÃ§Ãµes prÃ¡ticas dos exercÃ­cios de **MapReduce** e **PySpark**, desenvolvidos para a disciplina **Big Data e Cloud Computing**, ministrada pelo professor **Cristiano Neto** no **Ibmec BH**.

## COMO EXECUTAR OS EXERCÃCIOS 

### 1. Instalar dependÃªncias
Antes de comeÃ§ar, instale as bibliotecas necessÃ¡rias:

```bash
pip install -r requirements.txt

```
### 2. Executar via Docker 
O ambiente esteja configurado com Docker, rode:

docker run -it --rm -v "$(pwd):/app" atividade_mapreduce python pipeline.py


### EXERCÃCIOS 

ğŸ“ ExercÃ­cio 1 â€” WordCount
Implementa a contagem de palavras em Python puro, processando o arquivo test_input.txt e gerando results.txt com as ocorrÃªncias.

ğŸ“Š ExercÃ­cio 2 â€” Log Analysis
Realiza a anÃ¡lise de logs de servidor web (padrÃ£o Apache), extraindo:
IPs Ãºnicos
MÃ©todos HTTP (GET, POST, etc.)
URLs mais acessadas
DistribuiÃ§Ã£o de cÃ³digos de status

ğŸ’¬ ExercÃ­cio 3 â€” Sentiment Analysis
Processa o arquivo reviews.csv, classifica sentimentos (positivo, neutro, negativo) e gera estatÃ­sticas agregadas de feedbacks.

ğŸ’µ ExercÃ­cio 4 â€” Sales Aggregation
Analisa transaÃ§Ãµes de vendas em transactions.csv, produzindo totais de vendas por produto, cliente e categoria.

âš¡ ExercÃ­cio 5 â€” ImplementaÃ§Ãµes em PySpark
VersÃµes otimizadas com PySpark, para anÃ¡lise de grandes volumes de dados e comparaÃ§Ã£o de desempenho com Python puro.
5.1	WordCount em Spark
5.2	AnÃ¡lise de logs em Spark
5.3	AgregaÃ§Ã£o de vendas em Spark

### RESULTADOS 
Cada exercÃ­cio salva sua saÃ­da na pasta results/, podendo conter:
Arquivos .txt ou .csv
RelatÃ³rios agregados
VisualizaÃ§Ãµes (quando aplicÃ¡vel)
Dentro de cada exercÃ­cio tem uma aba respostas que mostra as conclusÃµes tiradas apÃ³s a realizaÃ§Ã£o dos cÃ³digos.

### TECNOLOGIAS UTILIZADAS 
Python 3.11
PySpark
Docker
Jupyter Notebook (para anÃ¡lise interativa opcional)
MapReduce (conceitos e implementaÃ§Ãµes manuais)
